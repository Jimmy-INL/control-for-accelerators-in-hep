{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed value\n",
    "# Apparently you may use different seed values at each stage\n",
    "seed_value= 0\n",
    "\n",
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "plt.rcParams['axes.titlesize'] = 18\n",
    "plt.rcParams['axes.titleweight'] = 'bold'\n",
    "plt.rcParams['axes.labelsize'] = 18\n",
    "plt.rcParams['axes.labelweight'] = 'regular'\n",
    "plt.rcParams['xtick.labelsize'] = 14\n",
    "plt.rcParams['ytick.labelsize'] = 14\n",
    "plt.rcParams['font.family'] = [u'serif']\n",
    "plt.rcParams['font.size'] = 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "249999\n",
      "Index(['time', 'file', 'I:IB', 'I:MDAT40', 'I:MXIB', 'B:LINFRQ', 'B:VIMIN',\n",
      "       'B:IMINER', 'B:VIMAX', 'B:VIPHAS'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import dataprep.dataset as dp\n",
    "filename='310_11_more_params.csv'#final_310_311_data.csv'\n",
    "nsteps=250000\n",
    "df = dp.load_reformated_cvs('../data/'+filename,nrows=nsteps)\n",
    "df['B:VIMIN'] = df['B:VIMIN'].shift(-1)\n",
    "#df['B:VIMIN_STD'] = df['B:VIMIN'].rolling(window=15).std()\n",
    "#df['B:IMINER_STD'] = df['B:IMINER'].rolling(window=15).std()\n",
    "df = df.set_index(pd.to_datetime(df.time))\n",
    "df = df.dropna()\n",
    "df = df.drop_duplicates()\n",
    "print(len(df))\n",
    "print(df.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(174847, 7, 150)\n",
      "(174847, 2)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "\n",
    "## 1 second (cycle - 15Hz)\n",
    "look_back    = 10*15 \n",
    "look_forward = 1 \n",
    "    \n",
    "def create_dataset(dataset, look_back=1,look_forward=1):\n",
    "    X, Y = [], []\n",
    "    offset = look_back+look_forward\n",
    "    for i in range(len(dataset)-(offset+1)):\n",
    "        xx = dataset[i:(i+look_back), 0]\n",
    "        yy = dataset[(i + look_back):(i + offset), 0]\n",
    "        X.append(xx)\n",
    "        Y.append(yy)\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "def get_dataset(variable='B:VIMIN'):\n",
    "\n",
    "    dataset = df[variable].values #numpy.ndarray\n",
    "    dataset = dataset.astype('float32')\n",
    "    dataset = np.reshape(dataset, (-1, 1))\n",
    "    scaler = MinMaxScaler(feature_range=(0.0001, 1))\n",
    "    #scaler = RobustScaler()\n",
    "    dataset = scaler.fit_transform(dataset)\n",
    "\n",
    "    ## TODO: Fix\n",
    "    #print(len(dataset))\n",
    "    train_size = int(len(dataset) * 0.70)\n",
    "    #print(train_size)\n",
    "    test_size = len(dataset) - train_size\n",
    "    #print(test_size)\n",
    "\n",
    "    train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "\n",
    "    X_train, Y_train = create_dataset(train, look_back,look_forward)\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "    Y_train = np.reshape(Y_train, (Y_train.shape[0],  Y_train.shape[1]))\n",
    "    #print(X_train.shape)\n",
    "    #print(Y_train.shape)\n",
    "    \n",
    "    X_test, Y_test = create_dataset(test, look_back,look_forward)\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "    Y_test = np.reshape(Y_test, (Y_test.shape[0],  Y_test.shape[1]))\n",
    "    #print(X_test.shape)\n",
    "    #print(Y_test.shape)\n",
    "    return scaler, X_train, Y_train, X_test, Y_test\n",
    "\n",
    "variables = ['B:VIMIN','B:IMINER','B:VIPHAS','B:LINFRQ','I:IB','I:MDAT40','I:MXIB']\n",
    "data_list = []\n",
    "x_train_list = []\n",
    "x_test_list = []\n",
    "for v in range(len(variables)):\n",
    "    data_list.append(get_dataset(variable=variables[v]))\n",
    "    x_train_list.append(data_list[v][1])\n",
    "    x_test_list.append(data_list[v][3])\n",
    "    \n",
    "# Axis\n",
    "concate_axis=1\n",
    "\n",
    "\n",
    "## Booster model data\n",
    "BoX_train = np.concatenate(x_train_list,axis=concate_axis) \n",
    "BoY_train = np.concatenate((data_list[0][2],data_list[1][2]),axis=1) \n",
    "BoX_test = np.concatenate(x_test_list,axis=concate_axis) \n",
    "BoY_test = np.concatenate((data_list[0][4],data_list[1][4]),axis=1) \n",
    "\n",
    "print(BoX_train.shape)\n",
    "print(BoY_train.shape)\n",
    "#from pickle import dump\n",
    "# save the scaler\n",
    "#for v in range(len(variables)):\n",
    "#    dump(data_list[v][0], open('t0_mmscaker_var{}_nsteps{}k_simple.pkl'.format(v,int(nsteps/1000)), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date and time: D10062020-T142555\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 7, 256)            416768    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 7, 256)            525312    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 1,467,906\n",
      "Trainable params: 1,467,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "########################\n",
      "### Running 0 split. ###\n",
      "### TrainX shape (139877, 7, 150)  ###\n",
      "### TrainY shape (139877, 2)  ###\n",
      "### ValX shape (34970, 7, 150)  ###\n",
      "### ValY shape (34970, 2)  ###\n",
      "########################\n",
      "Epoch 1/250\n",
      "1413/1413 - 15s - loss: 0.4100 - mse: 0.0260 - mape: 21.6816 - mae: 0.0578 - val_loss: 0.3265 - val_mse: 0.0045 - val_mape: 13.5259 - val_mae: 0.0453 - lr: 0.0100\n",
      "Epoch 2/250\n",
      "1413/1413 - 14s - loss: 0.3304 - mse: 0.0051 - mape: 18.1854 - mae: 0.0482 - val_loss: 0.3305 - val_mse: 0.0022 - val_mape: 9.1759 - val_mae: 0.0307 - lr: 0.0100\n",
      "Epoch 3/250\n",
      "1413/1413 - 14s - loss: 0.3260 - mse: 0.0016 - mape: 10.7354 - mae: 0.0265 - val_loss: 0.3244 - val_mse: 7.1768e-04 - val_mape: 5.3399 - val_mae: 0.0179 - lr: 0.0100\n",
      "Epoch 4/250\n",
      "1413/1413 - 14s - loss: 0.3250 - mse: 9.7269e-04 - mape: 7.3999 - mae: 0.0204 - val_loss: 0.3266 - val_mse: 7.7431e-04 - val_mape: 5.5483 - val_mae: 0.0185 - lr: 0.0100\n",
      "Epoch 5/250\n",
      "1413/1413 - 14s - loss: 0.3246 - mse: 9.0566e-04 - mape: 7.0308 - mae: 0.0197 - val_loss: 0.3202 - val_mse: 7.1201e-04 - val_mape: 5.3831 - val_mae: 0.0185 - lr: 0.0100\n",
      "Epoch 6/250\n",
      "1413/1413 - 14s - loss: 0.3246 - mse: 9.0389e-04 - mape: 7.2886 - mae: 0.0197 - val_loss: 0.3231 - val_mse: 7.3818e-04 - val_mape: 5.8479 - val_mae: 0.0187 - lr: 0.0100\n",
      "Epoch 7/250\n",
      "1413/1413 - 14s - loss: 0.3245 - mse: 8.9472e-04 - mape: 7.1798 - mae: 0.0197 - val_loss: 0.3212 - val_mse: 8.2347e-04 - val_mape: 6.4293 - val_mae: 0.0211 - lr: 0.0100\n",
      "Epoch 8/250\n",
      "1413/1413 - 14s - loss: 0.3245 - mse: 8.3513e-04 - mape: 6.9954 - mae: 0.0191 - val_loss: 0.3286 - val_mse: 5.9629e-04 - val_mape: 4.9881 - val_mae: 0.0164 - lr: 0.0100\n",
      "Epoch 9/250\n",
      "1413/1413 - 14s - loss: 0.3244 - mse: 8.0080e-04 - mape: 6.7550 - mae: 0.0186 - val_loss: 0.3240 - val_mse: 6.0725e-04 - val_mape: 4.9356 - val_mae: 0.0167 - lr: 0.0100\n",
      "Epoch 10/250\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.008499999810010194.\n",
      "1413/1413 - 14s - loss: 0.3244 - mse: 7.8840e-04 - mape: 6.6830 - mae: 0.0184 - val_loss: 0.3299 - val_mse: 6.8502e-04 - val_mape: 5.8458 - val_mae: 0.0183 - lr: 0.0100\n",
      "Epoch 11/250\n",
      "1413/1413 - 14s - loss: 0.2646 - mse: 7.5191e-04 - mape: 6.5132 - mae: 0.0179 - val_loss: 0.2731 - val_mse: 5.6703e-04 - val_mape: 4.7705 - val_mae: 0.0158 - lr: 0.0085\n",
      "Epoch 12/250\n",
      "1413/1413 - 14s - loss: 0.2654 - mse: 7.4934e-04 - mape: 6.3374 - mae: 0.0179 - val_loss: 0.2563 - val_mse: 5.7635e-04 - val_mape: 5.0131 - val_mae: 0.0160 - lr: 0.0085\n",
      "Epoch 13/250\n",
      "1413/1413 - 14s - loss: 0.2655 - mse: 7.3005e-04 - mape: 6.2492 - mae: 0.0176 - val_loss: 0.2658 - val_mse: 5.7154e-04 - val_mape: 4.6407 - val_mae: 0.0154 - lr: 0.0085\n",
      "Epoch 14/250\n",
      "1413/1413 - 14s - loss: 0.2655 - mse: 7.4445e-04 - mape: 6.2182 - mae: 0.0178 - val_loss: 0.2505 - val_mse: 5.8841e-04 - val_mape: 5.6244 - val_mae: 0.0171 - lr: 0.0085\n",
      "Epoch 15/250\n",
      "1413/1413 - 14s - loss: 0.2654 - mse: 7.2339e-04 - mape: 6.1298 - mae: 0.0175 - val_loss: 0.2835 - val_mse: 5.9920e-04 - val_mape: 4.8495 - val_mae: 0.0165 - lr: 0.0085\n",
      "Epoch 16/250\n",
      "1413/1413 - 14s - loss: 0.2655 - mse: 7.1979e-04 - mape: 6.1016 - mae: 0.0175 - val_loss: 0.2594 - val_mse: 6.2028e-04 - val_mape: 5.7201 - val_mae: 0.0177 - lr: 0.0085\n",
      "Epoch 17/250\n",
      "1413/1413 - 14s - loss: 0.2654 - mse: 7.1186e-04 - mape: 6.0195 - mae: 0.0173 - val_loss: 0.2632 - val_mse: 5.5522e-04 - val_mape: 4.8126 - val_mae: 0.0157 - lr: 0.0085\n",
      "Epoch 18/250\n",
      "1413/1413 - 14s - loss: 0.2655 - mse: 6.9538e-04 - mape: 6.1813 - mae: 0.0171 - val_loss: 0.2485 - val_mse: 5.6129e-04 - val_mape: 4.8936 - val_mae: 0.0161 - lr: 0.0085\n",
      "Epoch 19/250\n",
      "1413/1413 - 14s - loss: 0.2654 - mse: 7.0191e-04 - mape: 6.2756 - mae: 0.0172 - val_loss: 0.2785 - val_mse: 5.4111e-04 - val_mape: 4.5206 - val_mae: 0.0154 - lr: 0.0085\n",
      "Epoch 20/250\n",
      "1413/1413 - 14s - loss: 0.2654 - mse: 6.8885e-04 - mape: 5.8872 - mae: 0.0169 - val_loss: 0.2677 - val_mse: 5.7450e-04 - val_mape: 5.0107 - val_mae: 0.0164 - lr: 0.0085\n",
      "Epoch 21/250\n",
      "1413/1413 - 14s - loss: 0.2654 - mse: 6.7872e-04 - mape: 6.1426 - mae: 0.0168 - val_loss: 0.2602 - val_mse: 5.3218e-04 - val_mape: 4.5235 - val_mae: 0.0150 - lr: 0.0085\n",
      "Epoch 22/250\n",
      "1413/1413 - 14s - loss: 0.2655 - mse: 6.8356e-04 - mape: 6.1096 - mae: 0.0170 - val_loss: 0.2451 - val_mse: 6.8113e-04 - val_mape: 5.5187 - val_mae: 0.0177 - lr: 0.0085\n",
      "Epoch 23/250\n",
      "1413/1413 - 14s - loss: 0.2654 - mse: 6.8534e-04 - mape: 5.9957 - mae: 0.0170 - val_loss: 0.2757 - val_mse: 5.8030e-04 - val_mape: 4.6740 - val_mae: 0.0159 - lr: 0.0085\n",
      "Epoch 24/250\n",
      "1413/1413 - 14s - loss: 0.2655 - mse: 6.7173e-04 - mape: 6.0313 - mae: 0.0168 - val_loss: 0.2628 - val_mse: 5.1967e-04 - val_mape: 4.4969 - val_mae: 0.0150 - lr: 0.0085\n",
      "Epoch 25/250\n",
      "1413/1413 - 14s - loss: 0.2655 - mse: 6.8356e-04 - mape: 6.0676 - mae: 0.0169 - val_loss: 0.2633 - val_mse: 5.1078e-04 - val_mape: 4.4607 - val_mae: 0.0146 - lr: 0.0085\n",
      "Epoch 26/250\n",
      "1413/1413 - 14s - loss: 0.2655 - mse: 6.7462e-04 - mape: 6.0578 - mae: 0.0168 - val_loss: 0.2460 - val_mse: 5.7464e-04 - val_mape: 5.4154 - val_mae: 0.0168 - lr: 0.0085\n",
      "Epoch 27/250\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.007224999601021409.\n",
      "1413/1413 - 14s - loss: 0.2655 - mse: 6.7886e-04 - mape: 5.9040 - mae: 0.0169 - val_loss: 0.2748 - val_mse: 5.5457e-04 - val_mape: 4.8540 - val_mae: 0.0157 - lr: 0.0085\n",
      "Epoch 28/250\n",
      "1413/1413 - 14s - loss: 0.2216 - mse: 6.4508e-04 - mape: 5.8492 - mae: 0.0164 - val_loss: 0.2242 - val_mse: 5.6511e-04 - val_mape: 5.6294 - val_mae: 0.0169 - lr: 0.0072\n",
      "Epoch 29/250\n",
      "1413/1413 - 14s - loss: 0.2221 - mse: 6.5290e-04 - mape: 5.9043 - mae: 0.0165 - val_loss: 0.2142 - val_mse: 5.9274e-04 - val_mape: 4.6338 - val_mae: 0.0157 - lr: 0.0072\n",
      "Epoch 30/250\n",
      "1413/1413 - 14s - loss: 0.2221 - mse: 6.5070e-04 - mape: 6.0135 - mae: 0.0165 - val_loss: 0.2183 - val_mse: 5.0800e-04 - val_mape: 4.4314 - val_mae: 0.0147 - lr: 0.0072\n",
      "Epoch 31/250\n",
      "1413/1413 - 14s - loss: 0.2221 - mse: 6.4038e-04 - mape: 5.9036 - mae: 0.0163 - val_loss: 0.2284 - val_mse: 5.3643e-04 - val_mape: 5.0646 - val_mae: 0.0158 - lr: 0.0072\n",
      "Epoch 32/250\n",
      "1413/1413 - 14s - loss: 0.2221 - mse: 6.5264e-04 - mape: 5.8290 - mae: 0.0164 - val_loss: 0.2306 - val_mse: 5.3495e-04 - val_mape: 4.5003 - val_mae: 0.0154 - lr: 0.0072\n",
      "Epoch 33/250\n",
      "1413/1413 - 14s - loss: 0.2221 - mse: 6.3403e-04 - mape: 6.0260 - mae: 0.0163 - val_loss: 0.2162 - val_mse: 6.7964e-04 - val_mape: 5.0248 - val_mae: 0.0171 - lr: 0.0072\n",
      "Epoch 34/250\n",
      "\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.00614124946296215.\n",
      "1413/1413 - 14s - loss: 0.2221 - mse: 6.4221e-04 - mape: 5.7518 - mae: 0.0163 - val_loss: 0.2191 - val_mse: 5.4841e-04 - val_mape: 4.5957 - val_mae: 0.0156 - lr: 0.0072\n",
      "Epoch 35/250\n",
      "1413/1413 - 14s - loss: 0.1918 - mse: 6.1840e-04 - mape: 5.9289 - mae: 0.0161 - val_loss: 0.1952 - val_mse: 5.1212e-04 - val_mape: 4.6511 - val_mae: 0.0152 - lr: 0.0061\n",
      "Epoch 36/250\n",
      "1413/1413 - 14s - loss: 0.1927 - mse: 6.1077e-04 - mape: 5.5880 - mae: 0.0159 - val_loss: 0.1961 - val_mse: 4.9186e-04 - val_mape: 4.3373 - val_mae: 0.0145 - lr: 0.0061\n",
      "Epoch 37/250\n",
      "1413/1413 - 14s - loss: 0.1928 - mse: 6.0583e-04 - mape: 5.8153 - mae: 0.0160 - val_loss: 0.1855 - val_mse: 5.5431e-04 - val_mape: 4.8570 - val_mae: 0.0160 - lr: 0.0061\n",
      "Epoch 38/250\n",
      "1413/1413 - 14s - loss: 0.1928 - mse: 6.0751e-04 - mape: 5.4676 - mae: 0.0160 - val_loss: 0.1865 - val_mse: 5.1531e-04 - val_mape: 4.3669 - val_mae: 0.0145 - lr: 0.0061\n",
      "Epoch 39/250\n",
      "1413/1413 - 14s - loss: 0.1928 - mse: 6.0875e-04 - mape: 5.7443 - mae: 0.0160 - val_loss: 0.1952 - val_mse: 6.5744e-04 - val_mape: 5.0985 - val_mae: 0.0169 - lr: 0.0061\n",
      "Epoch 40/250\n",
      "1413/1413 - 14s - loss: 0.1927 - mse: 5.9927e-04 - mape: 5.4427 - mae: 0.0157 - val_loss: 0.1963 - val_mse: 5.1909e-04 - val_mape: 4.4195 - val_mae: 0.0146 - lr: 0.0061\n",
      "Epoch 41/250\n",
      "1413/1413 - 14s - loss: 0.1927 - mse: 6.0424e-04 - mape: 5.5594 - mae: 0.0159 - val_loss: 0.1898 - val_mse: 5.1104e-04 - val_mape: 4.6699 - val_mae: 0.0152 - lr: 0.0061\n",
      "Epoch 42/250\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.005220062122680246.\n",
      "1413/1413 - 14s - loss: 0.1927 - mse: 6.0410e-04 - mape: 5.4977 - mae: 0.0159 - val_loss: 0.1869 - val_mse: 4.8386e-04 - val_mape: 4.2187 - val_mae: 0.0141 - lr: 0.0061\n",
      "Epoch 43/250\n",
      "1413/1413 - 14s - loss: 0.1644 - mse: 5.8331e-04 - mape: 5.5514 - mae: 0.0156 - val_loss: 0.1664 - val_mse: 5.0576e-04 - val_mape: 4.3887 - val_mae: 0.0144 - lr: 0.0052\n",
      "Epoch 44/250\n",
      "1413/1413 - 14s - loss: 0.1645 - mse: 5.7674e-04 - mape: 5.4602 - mae: 0.0156 - val_loss: 0.1687 - val_mse: 5.3937e-04 - val_mape: 4.4935 - val_mae: 0.0154 - lr: 0.0052\n",
      "Epoch 45/250\n",
      "1413/1413 - 14s - loss: 0.1645 - mse: 5.7106e-04 - mape: 5.4208 - mae: 0.0155 - val_loss: 0.1607 - val_mse: 4.8979e-04 - val_mape: 4.3567 - val_mae: 0.0142 - lr: 0.0052\n",
      "Epoch 46/250\n",
      "1413/1413 - 14s - loss: 0.1645 - mse: 5.8656e-04 - mape: 5.5882 - mae: 0.0157 - val_loss: 0.1633 - val_mse: 5.3176e-04 - val_mape: 4.4508 - val_mae: 0.0153 - lr: 0.0052\n",
      "Epoch 47/250\n",
      "1413/1413 - 14s - loss: 0.1645 - mse: 5.7864e-04 - mape: 5.4814 - mae: 0.0155 - val_loss: 0.1667 - val_mse: 4.7088e-04 - val_mape: 4.1983 - val_mae: 0.0139 - lr: 0.0052\n",
      "Epoch 48/250\n",
      "1413/1413 - 14s - loss: 0.1645 - mse: 5.7580e-04 - mape: 5.2615 - mae: 0.0156 - val_loss: 0.1705 - val_mse: 5.4484e-04 - val_mape: 5.1030 - val_mae: 0.0165 - lr: 0.0052\n",
      "Epoch 49/250\n",
      "1413/1413 - 14s - loss: 0.1645 - mse: 5.6877e-04 - mape: 5.5488 - mae: 0.0155 - val_loss: 0.1598 - val_mse: 5.3194e-04 - val_mape: 4.4020 - val_mae: 0.0146 - lr: 0.0052\n",
      "Epoch 50/250\n",
      "1413/1413 - 14s - loss: 0.1645 - mse: 5.6563e-04 - mape: 5.2751 - mae: 0.0154 - val_loss: 0.1647 - val_mse: 4.9952e-04 - val_mape: 4.5636 - val_mae: 0.0146 - lr: 0.0052\n",
      "Epoch 51/250\n",
      "1413/1413 - 14s - loss: 0.1645 - mse: 5.8698e-04 - mape: 5.4590 - mae: 0.0157 - val_loss: 0.1655 - val_mse: 4.7867e-04 - val_mape: 4.2418 - val_mae: 0.0141 - lr: 0.0052\n",
      "Epoch 52/250\n",
      "1413/1413 - 14s - loss: 0.1645 - mse: 5.6208e-04 - mape: 5.3255 - mae: 0.0154 - val_loss: 0.1702 - val_mse: 5.1916e-04 - val_mape: 4.3322 - val_mae: 0.0145 - lr: 0.0052\n",
      "Epoch 53/250\n",
      "1413/1413 - 14s - loss: 0.1645 - mse: 5.6713e-04 - mape: 5.3755 - mae: 0.0155 - val_loss: 0.1607 - val_mse: 5.6800e-04 - val_mape: 4.9078 - val_mae: 0.0157 - lr: 0.0052\n",
      "Epoch 54/250\n",
      "\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 0.004437052784487605.\n",
      "1413/1413 - 14s - loss: 0.1645 - mse: 5.6454e-04 - mape: 5.3597 - mae: 0.0155 - val_loss: 0.1610 - val_mse: 5.3409e-04 - val_mape: 4.7265 - val_mae: 0.0152 - lr: 0.0052\n",
      "Epoch 55/250\n",
      "1413/1413 - 14s - loss: 0.1403 - mse: 5.5942e-04 - mape: 5.4468 - mae: 0.0153 - val_loss: 0.1435 - val_mse: 5.3077e-04 - val_mape: 4.3800 - val_mae: 0.0146 - lr: 0.0044\n",
      "Epoch 56/250\n",
      "1413/1413 - 14s - loss: 0.1404 - mse: 5.4849e-04 - mape: 5.3244 - mae: 0.0153 - val_loss: 0.1446 - val_mse: 4.7549e-04 - val_mape: 4.3757 - val_mae: 0.0141 - lr: 0.0044\n",
      "Epoch 57/250\n",
      "1413/1413 - 14s - loss: 0.1404 - mse: 5.5004e-04 - mape: 5.3418 - mae: 0.0152 - val_loss: 0.1380 - val_mse: 5.2343e-04 - val_mape: 4.4094 - val_mae: 0.0147 - lr: 0.0044\n",
      "Epoch 58/250\n",
      "1413/1413 - 14s - loss: 0.1404 - mse: 5.3791e-04 - mape: 5.5036 - mae: 0.0152 - val_loss: 0.1371 - val_mse: 4.7808e-04 - val_mape: 4.1798 - val_mae: 0.0138 - lr: 0.0044\n",
      "Epoch 59/250\n",
      "1413/1413 - 14s - loss: 0.1404 - mse: 5.5135e-04 - mape: 5.4659 - mae: 0.0152 - val_loss: 0.1421 - val_mse: 5.0608e-04 - val_mape: 4.3403 - val_mae: 0.0143 - lr: 0.0044\n",
      "Epoch 60/250\n",
      "1413/1413 - 14s - loss: 0.1404 - mse: 5.5388e-04 - mape: 5.2493 - mae: 0.0153 - val_loss: 0.1451 - val_mse: 5.0588e-04 - val_mape: 4.3090 - val_mae: 0.0145 - lr: 0.0044\n",
      "Epoch 61/250\n",
      "1413/1413 - 14s - loss: 0.1404 - mse: 5.4278e-04 - mape: 5.1898 - mae: 0.0151 - val_loss: 0.1361 - val_mse: 5.1171e-04 - val_mape: 4.4234 - val_mae: 0.0144 - lr: 0.0044\n",
      "Epoch 62/250\n",
      "1413/1413 - 14s - loss: 0.1404 - mse: 5.3996e-04 - mape: 5.3464 - mae: 0.0151 - val_loss: 0.1360 - val_mse: 4.8398e-04 - val_mape: 4.1946 - val_mae: 0.0139 - lr: 0.0044\n",
      "Epoch 63/250\n",
      "1413/1413 - 14s - loss: 0.1404 - mse: 5.3267e-04 - mape: 5.1092 - mae: 0.0151 - val_loss: 0.1437 - val_mse: 4.8254e-04 - val_mape: 4.1399 - val_mae: 0.0139 - lr: 0.0044\n",
      "Epoch 64/250\n",
      "1413/1413 - 14s - loss: 0.1404 - mse: 5.4208e-04 - mape: 5.3401 - mae: 0.0151 - val_loss: 0.1446 - val_mse: 4.8971e-04 - val_mape: 4.2814 - val_mae: 0.0143 - lr: 0.0044\n",
      "Epoch 65/250\n",
      "1413/1413 - 14s - loss: 0.1404 - mse: 5.3778e-04 - mape: 5.1560 - mae: 0.0151 - val_loss: 0.1383 - val_mse: 4.8736e-04 - val_mape: 4.1260 - val_mae: 0.0137 - lr: 0.0044\n",
      "Epoch 66/250\n",
      "1413/1413 - 14s - loss: 0.1404 - mse: 5.3023e-04 - mape: 5.2193 - mae: 0.0150 - val_loss: 0.1359 - val_mse: 4.9370e-04 - val_mape: 4.2251 - val_mae: 0.0139 - lr: 0.0044\n",
      "Epoch 67/250\n",
      "1413/1413 - 14s - loss: 0.1404 - mse: 5.2990e-04 - mape: 5.2569 - mae: 0.0150 - val_loss: 0.1456 - val_mse: 5.0022e-04 - val_mape: 4.3474 - val_mae: 0.0141 - lr: 0.0044\n",
      "Epoch 68/250\n",
      "1413/1413 - 14s - loss: 0.1404 - mse: 5.4840e-04 - mape: 5.2599 - mae: 0.0151 - val_loss: 0.1439 - val_mse: 5.1368e-04 - val_mape: 4.5209 - val_mae: 0.0144 - lr: 0.0044\n",
      "Epoch 69/250\n",
      "1413/1413 - 14s - loss: 0.1404 - mse: 5.5209e-04 - mape: 5.5513 - mae: 0.0152 - val_loss: 0.1370 - val_mse: 4.6957e-04 - val_mape: 4.2263 - val_mae: 0.0138 - lr: 0.0044\n",
      "Epoch 70/250\n",
      "1413/1413 - 14s - loss: 0.1404 - mse: 5.2726e-04 - mape: 5.2616 - mae: 0.0150 - val_loss: 0.1365 - val_mse: 5.6245e-04 - val_mape: 4.7646 - val_mae: 0.0158 - lr: 0.0044\n",
      "Epoch 71/250\n",
      "\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 0.003771494748070836.\n",
      "1413/1413 - 14s - loss: 0.1404 - mse: 5.4846e-04 - mape: 5.3815 - mae: 0.0151 - val_loss: 0.1444 - val_mse: 5.0273e-04 - val_mape: 4.2675 - val_mae: 0.0142 - lr: 0.0044\n",
      "Epoch 72/250\n",
      "1413/1413 - 14s - loss: 0.1198 - mse: 5.3026e-04 - mape: 5.1872 - mae: 0.0149 - val_loss: 0.1223 - val_mse: 4.7596e-04 - val_mape: 4.1922 - val_mae: 0.0138 - lr: 0.0038\n",
      "Epoch 73/250\n",
      "1413/1413 - 14s - loss: 0.1199 - mse: 5.1168e-04 - mape: 5.3155 - mae: 0.0148 - val_loss: 0.1169 - val_mse: 4.8272e-04 - val_mape: 4.1758 - val_mae: 0.0138 - lr: 0.0038\n",
      "Epoch 74/250\n",
      "1413/1413 - 14s - loss: 0.1199 - mse: 5.1175e-04 - mape: 4.9367 - mae: 0.0148 - val_loss: 0.1163 - val_mse: 4.8313e-04 - val_mape: 4.2496 - val_mae: 0.0139 - lr: 0.0038\n",
      "Epoch 75/250\n",
      "1413/1413 - 14s - loss: 0.1199 - mse: 5.1137e-04 - mape: 5.4054 - mae: 0.0149 - val_loss: 0.1228 - val_mse: 4.8656e-04 - val_mape: 4.2733 - val_mae: 0.0138 - lr: 0.0038\n",
      "Epoch 76/250\n",
      "1413/1413 - 14s - loss: 0.1199 - mse: 5.0828e-04 - mape: 5.2003 - mae: 0.0148 - val_loss: 0.1218 - val_mse: 4.8366e-04 - val_mape: 4.1500 - val_mae: 0.0136 - lr: 0.0038\n",
      "Epoch 77/250\n",
      "1413/1413 - 14s - loss: 0.1199 - mse: 5.1969e-04 - mape: 5.0660 - mae: 0.0148 - val_loss: 0.1184 - val_mse: 5.4736e-04 - val_mape: 4.6494 - val_mae: 0.0155 - lr: 0.0038\n",
      "Epoch 78/250\n",
      "1413/1413 - 14s - loss: 0.1199 - mse: 5.0858e-04 - mape: 5.1029 - mae: 0.0148 - val_loss: 0.1182 - val_mse: 5.0913e-04 - val_mape: 4.8850 - val_mae: 0.0152 - lr: 0.0038\n",
      "Epoch 79/250\n",
      "\n",
      "Epoch 00079: ReduceLROnPlateau reducing learning rate to 0.0032057706150226293.\n",
      "1413/1413 - 14s - loss: 0.1199 - mse: 5.0149e-04 - mape: 5.0864 - mae: 0.0147 - val_loss: 0.1239 - val_mse: 4.7660e-04 - val_mape: 4.2595 - val_mae: 0.0138 - lr: 0.0038\n",
      "Epoch 80/250\n",
      "1413/1413 - 14s - loss: 0.1024 - mse: 4.8975e-04 - mape: 5.0393 - mae: 0.0145 - val_loss: 0.1036 - val_mse: 4.8256e-04 - val_mape: 4.0781 - val_mae: 0.0135 - lr: 0.0032\n",
      "Epoch 81/250\n",
      "1413/1413 - 14s - loss: 0.1027 - mse: 5.0022e-04 - mape: 4.8591 - mae: 0.0146 - val_loss: 0.1012 - val_mse: 5.0303e-04 - val_mape: 4.4307 - val_mae: 0.0146 - lr: 0.0032\n",
      "Epoch 82/250\n",
      "1413/1413 - 14s - loss: 0.1027 - mse: 4.8903e-04 - mape: 4.8776 - mae: 0.0145 - val_loss: 0.1004 - val_mse: 5.8251e-04 - val_mape: 6.0144 - val_mae: 0.0173 - lr: 0.0032\n",
      "Epoch 83/250\n",
      "1413/1413 - 14s - loss: 0.1027 - mse: 4.9332e-04 - mape: 5.1959 - mae: 0.0146 - val_loss: 0.1042 - val_mse: 4.8300e-04 - val_mape: 4.1481 - val_mae: 0.0137 - lr: 0.0032\n",
      "Epoch 84/250\n",
      "1413/1413 - 14s - loss: 0.1027 - mse: 4.8105e-04 - mape: 4.8474 - mae: 0.0145 - val_loss: 0.1033 - val_mse: 4.9803e-04 - val_mape: 4.6014 - val_mae: 0.0145 - lr: 0.0032\n",
      "Epoch 85/250\n",
      "1413/1413 - 14s - loss: 0.1027 - mse: 4.9131e-04 - mape: 5.1813 - mae: 0.0145 - val_loss: 0.1017 - val_mse: 4.7414e-04 - val_mape: 4.4534 - val_mae: 0.0142 - lr: 0.0032\n",
      "Epoch 86/250\n",
      "1413/1413 - 14s - loss: 0.1027 - mse: 4.8283e-04 - mape: 5.0026 - mae: 0.0145 - val_loss: 0.0997 - val_mse: 4.8546e-04 - val_mape: 4.5873 - val_mae: 0.0145 - lr: 0.0032\n",
      "Epoch 87/250\n",
      "1413/1413 - 14s - loss: 0.1027 - mse: 4.9252e-04 - mape: 4.9879 - mae: 0.0146 - val_loss: 0.1043 - val_mse: 4.7706e-04 - val_mape: 4.2858 - val_mae: 0.0141 - lr: 0.0032\n",
      "Epoch 88/250\n",
      "1413/1413 - 14s - loss: 0.1027 - mse: 4.9185e-04 - mape: 5.2549 - mae: 0.0146 - val_loss: 0.1030 - val_mse: 4.7584e-04 - val_mape: 4.2769 - val_mae: 0.0140 - lr: 0.0032\n",
      "Epoch 89/250\n",
      "1413/1413 - 14s - loss: 0.1027 - mse: 4.7782e-04 - mape: 5.0007 - mae: 0.0144 - val_loss: 0.1014 - val_mse: 5.2523e-04 - val_mape: 4.3065 - val_mae: 0.0143 - lr: 0.0032\n",
      "Epoch 90/250\n",
      "1413/1413 - 14s - loss: 0.1027 - mse: 4.9660e-04 - mape: 5.1089 - mae: 0.0146 - val_loss: 0.1007 - val_mse: 5.2909e-04 - val_mape: 4.4715 - val_mae: 0.0149 - lr: 0.0032\n",
      "Epoch 91/250\n",
      "\n",
      "Epoch 00091: ReduceLROnPlateau reducing learning rate to 0.0027249050326645374.\n",
      "1413/1413 - 14s - loss: 0.1027 - mse: 4.7306e-04 - mape: 5.0869 - mae: 0.0144 - val_loss: 0.1038 - val_mse: 4.6503e-04 - val_mape: 4.2036 - val_mae: 0.0136 - lr: 0.0032\n",
      "Epoch 92/250\n",
      "1413/1413 - 14s - loss: 0.0873 - mse: 4.6655e-04 - mape: 4.8962 - mae: 0.0142 - val_loss: 0.0880 - val_mse: 4.9185e-04 - val_mape: 4.1242 - val_mae: 0.0136 - lr: 0.0027\n",
      "Epoch 93/250\n",
      "1413/1413 - 14s - loss: 0.0873 - mse: 4.6805e-04 - mape: 4.9872 - mae: 0.0143 - val_loss: 0.0860 - val_mse: 4.8856e-04 - val_mape: 4.0800 - val_mae: 0.0135 - lr: 0.0027\n",
      "Epoch 94/250\n",
      "1413/1413 - 14s - loss: 0.0873 - mse: 4.5517e-04 - mape: 4.9691 - mae: 0.0141 - val_loss: 0.0852 - val_mse: 4.6565e-04 - val_mape: 4.2879 - val_mae: 0.0137 - lr: 0.0027\n",
      "Epoch 95/250\n",
      "1413/1413 - 14s - loss: 0.0873 - mse: 4.6932e-04 - mape: 4.9569 - mae: 0.0143 - val_loss: 0.0888 - val_mse: 4.8252e-04 - val_mape: 4.1191 - val_mae: 0.0135 - lr: 0.0027\n",
      "Epoch 96/250\n",
      "1413/1413 - 14s - loss: 0.0873 - mse: 4.6148e-04 - mape: 4.8856 - mae: 0.0142 - val_loss: 0.0875 - val_mse: 4.5689e-04 - val_mape: 4.0114 - val_mae: 0.0132 - lr: 0.0027\n",
      "Epoch 97/250\n",
      "1413/1413 - 14s - loss: 0.0873 - mse: 4.6510e-04 - mape: 4.8968 - mae: 0.0143 - val_loss: 0.0862 - val_mse: 4.7377e-04 - val_mape: 4.1386 - val_mae: 0.0135 - lr: 0.0027\n",
      "Epoch 98/250\n",
      "1413/1413 - 14s - loss: 0.0873 - mse: 4.6526e-04 - mape: 4.9432 - mae: 0.0143 - val_loss: 0.0854 - val_mse: 4.7985e-04 - val_mape: 4.2663 - val_mae: 0.0139 - lr: 0.0027\n",
      "Epoch 99/250\n",
      "\n",
      "Epoch 00099: ReduceLROnPlateau reducing learning rate to 0.0023161692777648566.\n",
      "1413/1413 - 14s - loss: 0.0873 - mse: 4.6208e-04 - mape: 5.0419 - mae: 0.0142 - val_loss: 0.0884 - val_mse: 5.1188e-04 - val_mape: 4.7060 - val_mae: 0.0147 - lr: 0.0027\n",
      "Epoch 100/250\n",
      "1413/1413 - 14s - loss: 0.0743 - mse: 4.5745e-04 - mape: 4.9395 - mae: 0.0142 - val_loss: 0.0749 - val_mse: 4.7244e-04 - val_mape: 4.0760 - val_mae: 0.0135 - lr: 0.0023\n",
      "Epoch 101/250\n",
      "1413/1413 - 14s - loss: 0.0742 - mse: 4.4066e-04 - mape: 4.7265 - mae: 0.0139 - val_loss: 0.0730 - val_mse: 4.8536e-04 - val_mape: 4.1841 - val_mae: 0.0135 - lr: 0.0023\n",
      "Epoch 102/250\n",
      "1413/1413 - 14s - loss: 0.0743 - mse: 4.6129e-04 - mape: 5.1074 - mae: 0.0142 - val_loss: 0.0727 - val_mse: 4.7026e-04 - val_mape: 4.0805 - val_mae: 0.0135 - lr: 0.0023\n",
      "Epoch 103/250\n",
      "1413/1413 - 14s - loss: 0.0742 - mse: 4.4441e-04 - mape: 4.6958 - mae: 0.0139 - val_loss: 0.0754 - val_mse: 4.6737e-04 - val_mape: 4.0639 - val_mae: 0.0134 - lr: 0.0023\n",
      "Epoch 104/250\n",
      "1413/1413 - 14s - loss: 0.0742 - mse: 4.3849e-04 - mape: 4.7388 - mae: 0.0139 - val_loss: 0.0746 - val_mse: 4.6701e-04 - val_mape: 4.1389 - val_mae: 0.0136 - lr: 0.0023\n",
      "Epoch 105/250\n",
      "1413/1413 - 14s - loss: 0.0743 - mse: 4.4902e-04 - mape: 4.7923 - mae: 0.0140 - val_loss: 0.0734 - val_mse: 4.6759e-04 - val_mape: 4.4325 - val_mae: 0.0140 - lr: 0.0023\n",
      "Epoch 106/250\n",
      "1413/1413 - 14s - loss: 0.0742 - mse: 4.3409e-04 - mape: 4.7358 - mae: 0.0139 - val_loss: 0.0722 - val_mse: 4.8643e-04 - val_mape: 4.0552 - val_mae: 0.0134 - lr: 0.0023\n",
      "Epoch 107/250\n",
      "1413/1413 - 14s - loss: 0.0742 - mse: 4.4297e-04 - mape: 4.8023 - mae: 0.0140 - val_loss: 0.0754 - val_mse: 4.6964e-04 - val_mape: 4.3275 - val_mae: 0.0139 - lr: 0.0023\n",
      "Epoch 108/250\n",
      "1413/1413 - 14s - loss: 0.0742 - mse: 4.4832e-04 - mape: 4.7100 - mae: 0.0140 - val_loss: 0.0748 - val_mse: 4.7572e-04 - val_mape: 4.1713 - val_mae: 0.0135 - lr: 0.0023\n",
      "Epoch 109/250\n",
      "1413/1413 - 14s - loss: 0.0742 - mse: 4.4405e-04 - mape: 4.7923 - mae: 0.0140 - val_loss: 0.0731 - val_mse: 4.8982e-04 - val_mape: 4.1973 - val_mae: 0.0141 - lr: 0.0023\n",
      "Epoch 110/250\n",
      "1413/1413 - 14s - loss: 0.0742 - mse: 4.3195e-04 - mape: 4.7092 - mae: 0.0139 - val_loss: 0.0727 - val_mse: 4.7119e-04 - val_mape: 4.1214 - val_mae: 0.0135 - lr: 0.0023\n",
      "Epoch 111/250\n",
      "\n",
      "Epoch 00111: ReduceLROnPlateau reducing learning rate to 0.001968743826728314.\n",
      "1413/1413 - 14s - loss: 0.0742 - mse: 4.3077e-04 - mape: 4.6595 - mae: 0.0138 - val_loss: 0.0750 - val_mse: 4.7286e-04 - val_mape: 4.0242 - val_mae: 0.0133 - lr: 0.0023\n",
      "Epoch 112/250\n",
      "1413/1413 - 14s - loss: 0.0632 - mse: 4.2710e-04 - mape: 4.6022 - mae: 0.0137 - val_loss: 0.0636 - val_mse: 4.7465e-04 - val_mape: 4.1532 - val_mae: 0.0135 - lr: 0.0020\n",
      "Epoch 113/250\n",
      "1413/1413 - 14s - loss: 0.0632 - mse: 4.3002e-04 - mape: 4.7208 - mae: 0.0138 - val_loss: 0.0624 - val_mse: 5.0399e-04 - val_mape: 4.2614 - val_mae: 0.0140 - lr: 0.0020\n",
      "Epoch 114/250\n",
      "1413/1413 - 14s - loss: 0.0632 - mse: 4.3147e-04 - mape: 4.6819 - mae: 0.0138 - val_loss: 0.0616 - val_mse: 4.5003e-04 - val_mape: 4.0295 - val_mae: 0.0132 - lr: 0.0020\n",
      "Epoch 115/250\n",
      "1413/1413 - 14s - loss: 0.0632 - mse: 4.3372e-04 - mape: 4.5537 - mae: 0.0138 - val_loss: 0.0643 - val_mse: 4.6928e-04 - val_mape: 4.0420 - val_mae: 0.0133 - lr: 0.0020\n",
      "Epoch 116/250\n",
      "1413/1413 - 14s - loss: 0.0631 - mse: 4.1914e-04 - mape: 4.6791 - mae: 0.0136 - val_loss: 0.0634 - val_mse: 4.6059e-04 - val_mape: 4.0895 - val_mae: 0.0134 - lr: 0.0020\n",
      "Epoch 117/250\n",
      "1413/1413 - 14s - loss: 0.0632 - mse: 4.3531e-04 - mape: 4.6961 - mae: 0.0138 - val_loss: 0.0625 - val_mse: 4.6624e-04 - val_mape: 4.0135 - val_mae: 0.0132 - lr: 0.0020\n",
      "Epoch 118/250\n",
      "1413/1413 - 14s - loss: 0.0631 - mse: 4.2229e-04 - mape: 4.6613 - mae: 0.0136 - val_loss: 0.0616 - val_mse: 4.7079e-04 - val_mape: 4.1156 - val_mae: 0.0133 - lr: 0.0020\n",
      "Epoch 119/250\n",
      "\n",
      "Epoch 00119: ReduceLROnPlateau reducing learning rate to 0.0016734321834519506.\n",
      "1413/1413 - 14s - loss: 0.0632 - mse: 4.2873e-04 - mape: 4.6205 - mae: 0.0137 - val_loss: 0.0639 - val_mse: 4.7962e-04 - val_mape: 4.3165 - val_mae: 0.0138 - lr: 0.0020\n",
      "Epoch 120/250\n",
      "1413/1413 - 14s - loss: 0.0537 - mse: 4.1801e-04 - mape: 4.3880 - mae: 0.0136 - val_loss: 0.0543 - val_mse: 4.8519e-04 - val_mape: 4.1858 - val_mae: 0.0136 - lr: 0.0017\n",
      "Epoch 121/250\n",
      "1413/1413 - 14s - loss: 0.0537 - mse: 4.1193e-04 - mape: 4.6298 - mae: 0.0136 - val_loss: 0.0531 - val_mse: 4.9178e-04 - val_mape: 4.1686 - val_mae: 0.0135 - lr: 0.0017\n",
      "Epoch 122/250\n",
      "1413/1413 - 14s - loss: 0.0538 - mse: 4.1524e-04 - mape: 4.6282 - mae: 0.0136 - val_loss: 0.0527 - val_mse: 4.8043e-04 - val_mape: 4.4005 - val_mae: 0.0140 - lr: 0.0017\n",
      "Epoch 123/250\n",
      "1413/1413 - 14s - loss: 0.0538 - mse: 4.3319e-04 - mape: 4.6776 - mae: 0.0138 - val_loss: 0.0545 - val_mse: 4.5895e-04 - val_mape: 4.1503 - val_mae: 0.0134 - lr: 0.0017\n",
      "Epoch 124/250\n",
      "1413/1413 - 14s - loss: 0.0537 - mse: 4.0441e-04 - mape: 4.5584 - mae: 0.0134 - val_loss: 0.0541 - val_mse: 4.7314e-04 - val_mape: 4.0614 - val_mae: 0.0134 - lr: 0.0017\n",
      "Epoch 125/250\n",
      "1413/1413 - 14s - loss: 0.0538 - mse: 4.4143e-04 - mape: 4.5360 - mae: 0.0138 - val_loss: 0.0534 - val_mse: 4.9428e-04 - val_mape: 4.1826 - val_mae: 0.0137 - lr: 0.0017\n",
      "Epoch 126/250\n",
      "1413/1413 - 14s - loss: 0.0538 - mse: 4.2070e-04 - mape: 4.4762 - mae: 0.0136 - val_loss: 0.0523 - val_mse: 4.4498e-04 - val_mape: 4.0777 - val_mae: 0.0133 - lr: 0.0017\n",
      "Epoch 127/250\n",
      "1413/1413 - 14s - loss: 0.0537 - mse: 4.0540e-04 - mape: 4.4990 - mae: 0.0135 - val_loss: 0.0546 - val_mse: 4.8192e-04 - val_mape: 4.0939 - val_mae: 0.0135 - lr: 0.0017\n",
      "Epoch 128/250\n",
      "1413/1413 - 14s - loss: 0.0537 - mse: 4.1001e-04 - mape: 4.7298 - mae: 0.0135 - val_loss: 0.0541 - val_mse: 4.6115e-04 - val_mape: 3.9744 - val_mae: 0.0131 - lr: 0.0017\n",
      "Epoch 129/250\n",
      "1413/1413 - 14s - loss: 0.0537 - mse: 4.0885e-04 - mape: 4.5569 - mae: 0.0135 - val_loss: 0.0530 - val_mse: 4.5934e-04 - val_mape: 3.9949 - val_mae: 0.0131 - lr: 0.0017\n",
      "Epoch 130/250\n",
      "1413/1413 - 14s - loss: 0.0538 - mse: 4.1308e-04 - mape: 4.5126 - mae: 0.0135 - val_loss: 0.0527 - val_mse: 4.6671e-04 - val_mape: 4.1588 - val_mae: 0.0133 - lr: 0.0017\n",
      "Epoch 131/250\n",
      "\n",
      "Epoch 00131: ReduceLROnPlateau reducing learning rate to 0.0014224173559341578.\n",
      "1413/1413 - 14s - loss: 0.0537 - mse: 4.0338e-04 - mape: 4.4631 - mae: 0.0134 - val_loss: 0.0544 - val_mse: 4.5881e-04 - val_mape: 3.9416 - val_mae: 0.0130 - lr: 0.0017\n",
      "Epoch 132/250\n",
      "1413/1413 - 14s - loss: 0.0457 - mse: 3.9530e-04 - mape: 4.4107 - mae: 0.0133 - val_loss: 0.0461 - val_mse: 4.6727e-04 - val_mape: 4.0506 - val_mae: 0.0131 - lr: 0.0014\n",
      "Epoch 133/250\n",
      "1413/1413 - 14s - loss: 0.0458 - mse: 4.0600e-04 - mape: 4.5472 - mae: 0.0134 - val_loss: 0.0452 - val_mse: 4.5199e-04 - val_mape: 4.1623 - val_mae: 0.0136 - lr: 0.0014\n",
      "Epoch 134/250\n",
      "1413/1413 - 14s - loss: 0.0458 - mse: 3.9490e-04 - mape: 4.4545 - mae: 0.0133 - val_loss: 0.0447 - val_mse: 4.5900e-04 - val_mape: 4.0308 - val_mae: 0.0131 - lr: 0.0014\n",
      "Epoch 135/250\n",
      "1413/1413 - 14s - loss: 0.0458 - mse: 3.9586e-04 - mape: 4.5100 - mae: 0.0133 - val_loss: 0.0466 - val_mse: 4.6066e-04 - val_mape: 3.9493 - val_mae: 0.0130 - lr: 0.0014\n",
      "Epoch 136/250\n",
      "1413/1413 - 14s - loss: 0.0458 - mse: 3.9799e-04 - mape: 4.4273 - mae: 0.0133 - val_loss: 0.0460 - val_mse: 4.5587e-04 - val_mape: 4.0399 - val_mae: 0.0132 - lr: 0.0014\n",
      "Epoch 137/250\n",
      "1413/1413 - 14s - loss: 0.0458 - mse: 4.0149e-04 - mape: 4.4344 - mae: 0.0134 - val_loss: 0.0453 - val_mse: 4.9753e-04 - val_mape: 4.1008 - val_mae: 0.0134 - lr: 0.0014\n",
      "Epoch 138/250\n",
      "1413/1413 - 14s - loss: 0.0458 - mse: 3.9143e-04 - mape: 4.3532 - mae: 0.0132 - val_loss: 0.0447 - val_mse: 4.6583e-04 - val_mape: 3.9495 - val_mae: 0.0130 - lr: 0.0014\n",
      "Epoch 139/250\n",
      "\n",
      "Epoch 00139: ReduceLROnPlateau reducing learning rate to 0.001209054747596383.\n",
      "1413/1413 - 14s - loss: 0.0458 - mse: 3.9086e-04 - mape: 4.4485 - mae: 0.0132 - val_loss: 0.0464 - val_mse: 4.5086e-04 - val_mape: 3.9924 - val_mae: 0.0131 - lr: 0.0014\n",
      "Epoch 140/250\n",
      "1413/1413 - 14s - loss: 0.0389 - mse: 3.8794e-04 - mape: 4.3218 - mae: 0.0132 - val_loss: 0.0392 - val_mse: 4.5583e-04 - val_mape: 3.9388 - val_mae: 0.0130 - lr: 0.0012\n",
      "Epoch 141/250\n",
      "1413/1413 - 14s - loss: 0.0389 - mse: 3.8784e-04 - mape: 4.3361 - mae: 0.0132 - val_loss: 0.0384 - val_mse: 4.7555e-04 - val_mape: 4.0008 - val_mae: 0.0131 - lr: 0.0012\n",
      "Epoch 142/250\n",
      "1413/1413 - 14s - loss: 0.0389 - mse: 3.8561e-04 - mape: 4.2574 - mae: 0.0132 - val_loss: 0.0382 - val_mse: 4.6853e-04 - val_mape: 3.9924 - val_mae: 0.0131 - lr: 0.0012\n",
      "Epoch 143/250\n",
      "1413/1413 - 14s - loss: 0.0390 - mse: 3.9221e-04 - mape: 4.4194 - mae: 0.0132 - val_loss: 0.0395 - val_mse: 4.6738e-04 - val_mape: 4.0405 - val_mae: 0.0133 - lr: 0.0012\n",
      "Epoch 144/250\n",
      "1413/1413 - 14s - loss: 0.0389 - mse: 3.8283e-04 - mape: 4.3620 - mae: 0.0131 - val_loss: 0.0392 - val_mse: 4.5044e-04 - val_mape: 4.0550 - val_mae: 0.0131 - lr: 0.0012\n",
      "Epoch 145/250\n",
      "1413/1413 - 14s - loss: 0.0389 - mse: 3.8071e-04 - mape: 4.3256 - mae: 0.0131 - val_loss: 0.0386 - val_mse: 4.4813e-04 - val_mape: 3.9114 - val_mae: 0.0128 - lr: 0.0012\n",
      "Epoch 146/250\n",
      "1413/1413 - 14s - loss: 0.0390 - mse: 3.8985e-04 - mape: 4.4228 - mae: 0.0132 - val_loss: 0.0380 - val_mse: 4.5717e-04 - val_mape: 3.8959 - val_mae: 0.0129 - lr: 0.0012\n",
      "Epoch 147/250\n",
      "1413/1413 - 14s - loss: 0.0389 - mse: 3.8153e-04 - mape: 4.3661 - mae: 0.0131 - val_loss: 0.0396 - val_mse: 4.6085e-04 - val_mape: 4.1315 - val_mae: 0.0134 - lr: 0.0012\n",
      "Epoch 148/250\n",
      "1413/1413 - 14s - loss: 0.0389 - mse: 3.7967e-04 - mape: 4.2898 - mae: 0.0131 - val_loss: 0.0393 - val_mse: 4.6179e-04 - val_mape: 3.8907 - val_mae: 0.0129 - lr: 0.0012\n",
      "Epoch 149/250\n",
      "1413/1413 - 14s - loss: 0.0389 - mse: 3.8176e-04 - mape: 4.3615 - mae: 0.0131 - val_loss: 0.0384 - val_mse: 4.4475e-04 - val_mape: 4.0309 - val_mae: 0.0130 - lr: 0.0012\n",
      "Epoch 150/250\n",
      "1413/1413 - 14s - loss: 0.0390 - mse: 3.8395e-04 - mape: 4.4501 - mae: 0.0132 - val_loss: 0.0382 - val_mse: 4.4721e-04 - val_mape: 3.9260 - val_mae: 0.0129 - lr: 0.0012\n",
      "Epoch 151/250\n",
      "\n",
      "Epoch 00151: ReduceLROnPlateau reducing learning rate to 0.0010276965156663209.\n",
      "1413/1413 - 14s - loss: 0.0389 - mse: 3.8030e-04 - mape: 4.3302 - mae: 0.0131 - val_loss: 0.0394 - val_mse: 4.4021e-04 - val_mape: 4.0306 - val_mae: 0.0132 - lr: 0.0012\n",
      "Epoch 152/250\n",
      "1413/1413 - 14s - loss: 0.0332 - mse: 3.7619e-04 - mape: 4.2700 - mae: 0.0130 - val_loss: 0.0332 - val_mse: 4.3415e-04 - val_mape: 3.8986 - val_mae: 0.0128 - lr: 0.0010\n",
      "Epoch 153/250\n",
      "1413/1413 - 14s - loss: 0.0332 - mse: 3.7527e-04 - mape: 4.3208 - mae: 0.0130 - val_loss: 0.0328 - val_mse: 4.6289e-04 - val_mape: 3.9892 - val_mae: 0.0130 - lr: 0.0010\n",
      "Epoch 154/250\n",
      "1413/1413 - 14s - loss: 0.0331 - mse: 3.7259e-04 - mape: 4.2393 - mae: 0.0130 - val_loss: 0.0324 - val_mse: 4.3611e-04 - val_mape: 3.8798 - val_mae: 0.0128 - lr: 0.0010\n",
      "Epoch 155/250\n",
      "1413/1413 - 14s - loss: 0.0332 - mse: 3.7681e-04 - mape: 4.2879 - mae: 0.0130 - val_loss: 0.0339 - val_mse: 4.4964e-04 - val_mape: 3.9675 - val_mae: 0.0131 - lr: 0.0010\n",
      "Epoch 156/250\n",
      "1413/1413 - 14s - loss: 0.0332 - mse: 3.7724e-04 - mape: 4.2014 - mae: 0.0130 - val_loss: 0.0333 - val_mse: 4.5882e-04 - val_mape: 3.9225 - val_mae: 0.0129 - lr: 0.0010\n",
      "Epoch 157/250\n",
      "1413/1413 - 14s - loss: 0.0331 - mse: 3.6985e-04 - mape: 4.2516 - mae: 0.0129 - val_loss: 0.0328 - val_mse: 4.4596e-04 - val_mape: 3.9175 - val_mae: 0.0130 - lr: 0.0010\n",
      "Epoch 158/250\n",
      "1413/1413 - 14s - loss: 0.0332 - mse: 3.7228e-04 - mape: 4.3058 - mae: 0.0129 - val_loss: 0.0324 - val_mse: 4.3648e-04 - val_mape: 3.8629 - val_mae: 0.0127 - lr: 0.0010\n",
      "Epoch 159/250\n",
      "\n",
      "Epoch 00159: ReduceLROnPlateau reducing learning rate to 0.0008735420531593263.\n",
      "1413/1413 - 14s - loss: 0.0331 - mse: 3.6743e-04 - mape: 4.3032 - mae: 0.0129 - val_loss: 0.0336 - val_mse: 4.4015e-04 - val_mape: 3.8954 - val_mae: 0.0128 - lr: 0.0010\n",
      "Epoch 160/250\n",
      "1413/1413 - 14s - loss: 0.0282 - mse: 3.6725e-04 - mape: 4.1853 - mae: 0.0128 - val_loss: 0.0283 - val_mse: 4.4044e-04 - val_mape: 3.9198 - val_mae: 0.0129 - lr: 8.7354e-04\n",
      "Epoch 161/250\n",
      "1413/1413 - 14s - loss: 0.0282 - mse: 3.6436e-04 - mape: 4.2883 - mae: 0.0128 - val_loss: 0.0278 - val_mse: 4.3887e-04 - val_mape: 3.8796 - val_mae: 0.0127 - lr: 8.7354e-04\n",
      "Epoch 162/250\n",
      "1413/1413 - 14s - loss: 0.0282 - mse: 3.6966e-04 - mape: 4.1763 - mae: 0.0129 - val_loss: 0.0277 - val_mse: 4.5236e-04 - val_mape: 3.9724 - val_mae: 0.0130 - lr: 8.7354e-04\n",
      "Epoch 163/250\n",
      "1413/1413 - 14s - loss: 0.0282 - mse: 3.6502e-04 - mape: 4.3040 - mae: 0.0128 - val_loss: 0.0287 - val_mse: 4.4061e-04 - val_mape: 4.0787 - val_mae: 0.0132 - lr: 8.7354e-04\n",
      "Epoch 164/250\n",
      "1413/1413 - 14s - loss: 0.0282 - mse: 3.6804e-04 - mape: 4.3310 - mae: 0.0129 - val_loss: 0.0285 - val_mse: 4.5445e-04 - val_mape: 4.1389 - val_mae: 0.0134 - lr: 8.7354e-04\n",
      "Epoch 165/250\n",
      "1413/1413 - 14s - loss: 0.0282 - mse: 3.6698e-04 - mape: 4.2830 - mae: 0.0128 - val_loss: 0.0280 - val_mse: 4.5233e-04 - val_mape: 3.9187 - val_mae: 0.0128 - lr: 8.7354e-04\n",
      "Epoch 166/250\n",
      "1413/1413 - 14s - loss: 0.0282 - mse: 3.5984e-04 - mape: 4.3078 - mae: 0.0127 - val_loss: 0.0276 - val_mse: 4.5482e-04 - val_mape: 4.1531 - val_mae: 0.0132 - lr: 8.7354e-04\n",
      "Epoch 167/250\n",
      "1413/1413 - 14s - loss: 0.0282 - mse: 3.6019e-04 - mape: 4.1705 - mae: 0.0128 - val_loss: 0.0289 - val_mse: 5.5893e-04 - val_mape: 5.3246 - val_mae: 0.0165 - lr: 8.7354e-04\n",
      "Epoch 168/250\n",
      "1413/1413 - 14s - loss: 0.0282 - mse: 3.6420e-04 - mape: 4.2688 - mae: 0.0128 - val_loss: 0.0285 - val_mse: 4.4445e-04 - val_mape: 3.8724 - val_mae: 0.0127 - lr: 8.7354e-04\n",
      "Epoch 169/250\n",
      "1413/1413 - 14s - loss: 0.0282 - mse: 3.5666e-04 - mape: 4.0353 - mae: 0.0127 - val_loss: 0.0279 - val_mse: 4.4533e-04 - val_mape: 3.9881 - val_mae: 0.0129 - lr: 8.7354e-04\n",
      "Epoch 170/250\n",
      "1413/1413 - 14s - loss: 0.0282 - mse: 3.5879e-04 - mape: 4.2048 - mae: 0.0127 - val_loss: 0.0278 - val_mse: 4.4771e-04 - val_mape: 3.9792 - val_mae: 0.0130 - lr: 8.7354e-04\n",
      "Epoch 171/250\n",
      "\n",
      "Epoch 00171: ReduceLROnPlateau reducing learning rate to 0.000742510735290125.\n",
      "1413/1413 - 14s - loss: 0.0282 - mse: 3.5674e-04 - mape: 4.2170 - mae: 0.0127 - val_loss: 0.0286 - val_mse: 4.4536e-04 - val_mape: 3.9928 - val_mae: 0.0130 - lr: 8.7354e-04\n",
      "Epoch 172/250\n",
      "1413/1413 - 14s - loss: 0.0240 - mse: 3.5461e-04 - mape: 4.1661 - mae: 0.0127 - val_loss: 0.0240 - val_mse: 4.5181e-04 - val_mape: 3.8817 - val_mae: 0.0128 - lr: 7.4251e-04\n",
      "Epoch 173/250\n",
      "1413/1413 - 14s - loss: 0.0240 - mse: 3.5245e-04 - mape: 4.1989 - mae: 0.0126 - val_loss: 0.0238 - val_mse: 4.4411e-04 - val_mape: 3.8327 - val_mae: 0.0126 - lr: 7.4251e-04\n",
      "Epoch 174/250\n",
      "1413/1413 - 14s - loss: 0.0240 - mse: 3.5365e-04 - mape: 4.1876 - mae: 0.0126 - val_loss: 0.0235 - val_mse: 4.3860e-04 - val_mape: 3.8568 - val_mae: 0.0127 - lr: 7.4251e-04\n",
      "Epoch 175/250\n",
      "1413/1413 - 14s - loss: 0.0240 - mse: 3.5170e-04 - mape: 4.2291 - mae: 0.0126 - val_loss: 0.0245 - val_mse: 4.3465e-04 - val_mape: 3.9235 - val_mae: 0.0127 - lr: 7.4251e-04\n",
      "Epoch 176/250\n",
      "1413/1413 - 14s - loss: 0.0240 - mse: 3.5039e-04 - mape: 4.1486 - mae: 0.0126 - val_loss: 0.0242 - val_mse: 4.3255e-04 - val_mape: 3.8476 - val_mae: 0.0126 - lr: 7.4251e-04\n",
      "Epoch 177/250\n",
      "1413/1413 - 14s - loss: 0.0240 - mse: 3.5169e-04 - mape: 4.1864 - mae: 0.0126 - val_loss: 0.0238 - val_mse: 4.3240e-04 - val_mape: 3.8594 - val_mae: 0.0126 - lr: 7.4251e-04\n",
      "Epoch 178/250\n",
      "1413/1413 - 14s - loss: 0.0240 - mse: 3.5050e-04 - mape: 4.1820 - mae: 0.0126 - val_loss: 0.0236 - val_mse: 4.3933e-04 - val_mape: 4.0824 - val_mae: 0.0131 - lr: 7.4251e-04\n",
      "Epoch 179/250\n",
      "\n",
      "Epoch 00179: ReduceLROnPlateau reducing learning rate to 0.0006311341101536527.\n",
      "1413/1413 - 14s - loss: 0.0240 - mse: 3.5130e-04 - mape: 4.1801 - mae: 0.0126 - val_loss: 0.0245 - val_mse: 4.6023e-04 - val_mape: 3.9542 - val_mae: 0.0129 - lr: 7.4251e-04\n",
      "Epoch 180/250\n",
      "1413/1413 - 14s - loss: 0.0205 - mse: 3.4660e-04 - mape: 4.1427 - mae: 0.0125 - val_loss: 0.0203 - val_mse: 4.3416e-04 - val_mape: 3.8427 - val_mae: 0.0126 - lr: 6.3113e-04\n",
      "Epoch 181/250\n",
      "1413/1413 - 14s - loss: 0.0205 - mse: 3.4686e-04 - mape: 4.2087 - mae: 0.0125 - val_loss: 0.0202 - val_mse: 4.3352e-04 - val_mape: 3.8884 - val_mae: 0.0128 - lr: 6.3113e-04\n",
      "Epoch 182/250\n",
      "1413/1413 - 14s - loss: 0.0205 - mse: 3.4569e-04 - mape: 4.0865 - mae: 0.0125 - val_loss: 0.0201 - val_mse: 4.2689e-04 - val_mape: 3.8412 - val_mae: 0.0125 - lr: 6.3113e-04\n",
      "Epoch 183/250\n",
      "1413/1413 - 14s - loss: 0.0205 - mse: 3.4517e-04 - mape: 4.1194 - mae: 0.0125 - val_loss: 0.0208 - val_mse: 4.3077e-04 - val_mape: 3.8930 - val_mae: 0.0126 - lr: 6.3113e-04\n",
      "Epoch 184/250\n",
      "1413/1413 - 14s - loss: 0.0205 - mse: 3.4307e-04 - mape: 4.1372 - mae: 0.0124 - val_loss: 0.0207 - val_mse: 4.4440e-04 - val_mape: 3.8499 - val_mae: 0.0127 - lr: 6.3113e-04\n",
      "Epoch 185/250\n",
      "1413/1413 - 14s - loss: 0.0205 - mse: 3.4536e-04 - mape: 4.1374 - mae: 0.0125 - val_loss: 0.0204 - val_mse: 4.3152e-04 - val_mape: 3.9275 - val_mae: 0.0127 - lr: 6.3113e-04\n",
      "Epoch 186/250\n",
      "1413/1413 - 14s - loss: 0.0205 - mse: 3.4857e-04 - mape: 4.0761 - mae: 0.0125 - val_loss: 0.0200 - val_mse: 4.2672e-04 - val_mape: 3.8916 - val_mae: 0.0127 - lr: 6.3113e-04\n",
      "Epoch 187/250\n",
      "\n",
      "Epoch 00187: ReduceLROnPlateau reducing learning rate to 0.0005364639713661745.\n",
      "1413/1413 - 14s - loss: 0.0205 - mse: 3.4157e-04 - mape: 4.0954 - mae: 0.0124 - val_loss: 0.0209 - val_mse: 4.2909e-04 - val_mape: 3.8526 - val_mae: 0.0126 - lr: 6.3113e-04\n",
      "Epoch 188/250\n",
      "1413/1413 - 14s - loss: 0.0174 - mse: 3.3866e-04 - mape: 4.0459 - mae: 0.0123 - val_loss: 0.0172 - val_mse: 4.2135e-04 - val_mape: 3.9090 - val_mae: 0.0127 - lr: 5.3646e-04\n",
      "Epoch 189/250\n",
      "1413/1413 - 14s - loss: 0.0175 - mse: 3.3924e-04 - mape: 4.0277 - mae: 0.0124 - val_loss: 0.0173 - val_mse: 4.3019e-04 - val_mape: 3.8866 - val_mae: 0.0126 - lr: 5.3646e-04\n",
      "Epoch 190/250\n",
      "1413/1413 - 14s - loss: 0.0175 - mse: 3.3890e-04 - mape: 4.0806 - mae: 0.0123 - val_loss: 0.0172 - val_mse: 4.3142e-04 - val_mape: 3.8829 - val_mae: 0.0126 - lr: 5.3646e-04\n",
      "Epoch 191/250\n",
      "1413/1413 - 14s - loss: 0.0175 - mse: 3.3767e-04 - mape: 4.1525 - mae: 0.0123 - val_loss: 0.0177 - val_mse: 4.2220e-04 - val_mape: 3.8888 - val_mae: 0.0126 - lr: 5.3646e-04\n",
      "Epoch 192/250\n",
      "1413/1413 - 14s - loss: 0.0175 - mse: 3.3779e-04 - mape: 4.0755 - mae: 0.0123 - val_loss: 0.0177 - val_mse: 4.2252e-04 - val_mape: 3.8676 - val_mae: 0.0126 - lr: 5.3646e-04\n",
      "Epoch 193/250\n",
      "\n",
      "Epoch 00193: ReduceLROnPlateau reducing learning rate to 0.0004559943830827251.\n",
      "1413/1413 - 14s - loss: 0.0175 - mse: 3.3730e-04 - mape: 4.0634 - mae: 0.0123 - val_loss: 0.0173 - val_mse: 4.2501e-04 - val_mape: 3.8370 - val_mae: 0.0125 - lr: 5.3646e-04\n",
      "Epoch 194/250\n",
      "1413/1413 - 14s - loss: 0.0149 - mse: 3.3488e-04 - mape: 3.9960 - mae: 0.0123 - val_loss: 0.0142 - val_mse: 4.2241e-04 - val_mape: 3.8106 - val_mae: 0.0125 - lr: 4.5599e-04\n",
      "Epoch 195/250\n",
      "1413/1413 - 14s - loss: 0.0149 - mse: 3.3368e-04 - mape: 3.9956 - mae: 0.0122 - val_loss: 0.0152 - val_mse: 4.2010e-04 - val_mape: 3.8104 - val_mae: 0.0125 - lr: 4.5599e-04\n",
      "Epoch 196/250\n",
      "1413/1413 - 14s - loss: 0.0149 - mse: 3.3429e-04 - mape: 4.0511 - mae: 0.0123 - val_loss: 0.0149 - val_mse: 4.1790e-04 - val_mape: 3.8754 - val_mae: 0.0125 - lr: 4.5599e-04\n",
      "Epoch 197/250\n",
      "1413/1413 - 14s - loss: 0.0149 - mse: 3.3301e-04 - mape: 4.0805 - mae: 0.0122 - val_loss: 0.0145 - val_mse: 4.2158e-04 - val_mape: 3.8517 - val_mae: 0.0125 - lr: 4.5599e-04\n",
      "Epoch 198/250\n",
      "1413/1413 - 14s - loss: 0.0149 - mse: 3.3290e-04 - mape: 3.9869 - mae: 0.0122 - val_loss: 0.0149 - val_mse: 4.1842e-04 - val_mape: 3.8417 - val_mae: 0.0125 - lr: 4.5599e-04\n",
      "Epoch 199/250\n",
      "\n",
      "Epoch 00199: ReduceLROnPlateau reducing learning rate to 0.0003875952330417931.\n",
      "1413/1413 - 14s - loss: 0.0149 - mse: 3.3223e-04 - mape: 4.0659 - mae: 0.0122 - val_loss: 0.0157 - val_mse: 4.1631e-04 - val_mape: 3.8904 - val_mae: 0.0126 - lr: 4.5599e-04\n",
      "Epoch 200/250\n",
      "1413/1413 - 14s - loss: 0.0127 - mse: 3.2980e-04 - mape: 4.0832 - mae: 0.0122 - val_loss: 0.0125 - val_mse: 4.2340e-04 - val_mape: 3.8786 - val_mae: 0.0126 - lr: 3.8760e-04\n",
      "Epoch 201/250\n",
      "1413/1413 - 14s - loss: 0.0127 - mse: 3.2995e-04 - mape: 3.9960 - mae: 0.0122 - val_loss: 0.0124 - val_mse: 4.1936e-04 - val_mape: 3.7843 - val_mae: 0.0124 - lr: 3.8760e-04\n",
      "Epoch 202/250\n",
      "1413/1413 - 14s - loss: 0.0127 - mse: 3.2930e-04 - mape: 3.9818 - mae: 0.0121 - val_loss: 0.0127 - val_mse: 4.2495e-04 - val_mape: 3.9057 - val_mae: 0.0126 - lr: 3.8760e-04\n",
      "Epoch 203/250\n",
      "1413/1413 - 14s - loss: 0.0127 - mse: 3.2942e-04 - mape: 3.9653 - mae: 0.0121 - val_loss: 0.0134 - val_mse: 4.2547e-04 - val_mape: 3.9254 - val_mae: 0.0126 - lr: 3.8760e-04\n",
      "Epoch 204/250\n",
      "1413/1413 - 14s - loss: 0.0127 - mse: 3.2930e-04 - mape: 4.0147 - mae: 0.0121 - val_loss: 0.0130 - val_mse: 4.1625e-04 - val_mape: 3.8920 - val_mae: 0.0126 - lr: 3.8760e-04\n",
      "Epoch 205/250\n",
      "1413/1413 - 14s - loss: 0.0127 - mse: 3.2864e-04 - mape: 3.9860 - mae: 0.0121 - val_loss: 0.0125 - val_mse: 4.1289e-04 - val_mape: 3.8692 - val_mae: 0.0125 - lr: 3.8760e-04\n",
      "Epoch 206/250\n",
      "\n",
      "Epoch 00206: ReduceLROnPlateau reducing learning rate to 0.0003294559530331753.\n",
      "1413/1413 - 14s - loss: 0.0127 - mse: 3.2790e-04 - mape: 4.0153 - mae: 0.0121 - val_loss: 0.0126 - val_mse: 4.1609e-04 - val_mape: 3.7993 - val_mae: 0.0124 - lr: 3.8760e-04\n",
      "Epoch 207/250\n",
      "1413/1413 - 14s - loss: 0.0108 - mse: 3.2633e-04 - mape: 3.9019 - mae: 0.0121 - val_loss: 0.0107 - val_mse: 4.1540e-04 - val_mape: 3.8169 - val_mae: 0.0124 - lr: 3.2946e-04\n",
      "Epoch 208/250\n",
      "1413/1413 - 14s - loss: 0.0108 - mse: 3.2590e-04 - mape: 3.9949 - mae: 0.0121 - val_loss: 0.0107 - val_mse: 4.2154e-04 - val_mape: 3.9239 - val_mae: 0.0127 - lr: 3.2946e-04\n",
      "Epoch 209/250\n",
      "1413/1413 - 14s - loss: 0.0108 - mse: 3.2497e-04 - mape: 3.9563 - mae: 0.0120 - val_loss: 0.0105 - val_mse: 4.1591e-04 - val_mape: 3.8787 - val_mae: 0.0125 - lr: 3.2946e-04\n",
      "Epoch 210/250\n",
      "1413/1413 - 14s - loss: 0.0108 - mse: 3.2566e-04 - mape: 4.0190 - mae: 0.0121 - val_loss: 0.0110 - val_mse: 4.1832e-04 - val_mape: 3.7801 - val_mae: 0.0123 - lr: 3.2946e-04\n",
      "Epoch 211/250\n",
      "1413/1413 - 14s - loss: 0.0108 - mse: 3.2466e-04 - mape: 4.0122 - mae: 0.0120 - val_loss: 0.0114 - val_mse: 4.1712e-04 - val_mape: 3.8220 - val_mae: 0.0125 - lr: 3.2946e-04\n",
      "Epoch 212/250\n",
      "1413/1413 - 14s - loss: 0.0108 - mse: 3.2419e-04 - mape: 4.0563 - mae: 0.0120 - val_loss: 0.0108 - val_mse: 4.1509e-04 - val_mape: 3.8423 - val_mae: 0.0124 - lr: 3.2946e-04\n",
      "Epoch 213/250\n",
      "1413/1413 - 14s - loss: 0.0108 - mse: 3.2430e-04 - mape: 3.9417 - mae: 0.0120 - val_loss: 0.0109 - val_mse: 4.1490e-04 - val_mape: 3.8107 - val_mae: 0.0124 - lr: 3.2946e-04\n",
      "Epoch 214/250\n",
      "\n",
      "Epoch 00214: ReduceLROnPlateau reducing learning rate to 0.00028003755141980946.\n",
      "1413/1413 - 14s - loss: 0.0108 - mse: 3.2349e-04 - mape: 4.0454 - mae: 0.0120 - val_loss: 0.0111 - val_mse: 4.1072e-04 - val_mape: 3.7893 - val_mae: 0.0124 - lr: 3.2946e-04\n",
      "Epoch 215/250\n",
      "1413/1413 - 14s - loss: 0.0093 - mse: 3.2161e-04 - mape: 3.9228 - mae: 0.0120 - val_loss: 0.0092 - val_mse: 4.1656e-04 - val_mape: 3.7998 - val_mae: 0.0124 - lr: 2.8004e-04\n",
      "Epoch 216/250\n",
      "1413/1413 - 14s - loss: 0.0093 - mse: 3.2142e-04 - mape: 3.9971 - mae: 0.0120 - val_loss: 0.0094 - val_mse: 4.1518e-04 - val_mape: 3.8513 - val_mae: 0.0124 - lr: 2.8004e-04\n",
      "Epoch 217/250\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "\n",
    "import src.analysis as ana\n",
    "import src.models as models\n",
    "e=250\n",
    "bs=99\n",
    "in_shape=(len(variables),150)\n",
    "if concate_axis==2:\n",
    "    in_shape=(1,len(variables)*150)\n",
    "    \n",
    "start_time=time.time()\n",
    "now = datetime.now()\n",
    "timestamp = now.strftime(\"D%m%d%Y-T%H%M%S\")\n",
    "print(\"date and time:\", timestamp)\n",
    "##\n",
    "save_name='fullbooster_e{}_bs{}_nsteps{}k_nvar{}_axis{}_mmscaler_t0_{}'.format(e,bs,int(nsteps/1000),len(variables),concate_axis,timestamp)\n",
    "\n",
    "## Callbacks\n",
    "#tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"./logs\")\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss',factor=0.85, patience=5, min_lr=1e-6,verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss',min_delta=0, patience=10, verbose=1, mode='auto',\n",
    "                               baseline=None, restore_best_weights=False)\n",
    "\n",
    "## Model \n",
    "booster_model = models.build_lstm_model(input_shape=in_shape,output_shape=2)\n",
    "opt = Adam(lr=1e-2,clipnorm=1.0, clipvalue=0.5)\n",
    "#booster_model.compile(loss='mean_squared_error', optimizer=opt,metrics=['mape','mae'])\n",
    "booster_model.compile(loss='mse', optimizer=opt,metrics=['mse','mape','mae'])\n",
    "booster_model.summary()\n",
    "\n",
    "## Run multiple versions \n",
    "histories = []\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5, random_state=None, shuffle=False)\n",
    "k=0\n",
    "for train_index, val_index in kf.split(BoX_train):\n",
    "    ## Prep data\n",
    "    x_train, x_val = BoX_train[train_index], BoX_train[val_index]\n",
    "    y_train, y_val = BoY_train[train_index], BoY_train[val_index]\n",
    "    print('########################')\n",
    "    print('### Running {} split. ###'.format(k))\n",
    "    print('### TrainX shape {}  ###'.format(x_train.shape))\n",
    "    print('### TrainY shape {}  ###'.format(y_train.shape))\n",
    "    print('### ValX shape {}  ###'.format(x_val.shape))\n",
    "    print('### ValY shape {}  ###'.format(y_val.shape))\n",
    "    print('########################')\n",
    "    ## Save best model callback\n",
    "    mcp_name=save_name+'_ksplit{}_'.format(k)\n",
    "    mcp_save = tf.keras.callbacks.ModelCheckpoint(filepath='models/'+mcp_name+'_e{epoch:02d}_vl{val_loss:.2f}.h5')\n",
    "    ## Run model\n",
    "    history = booster_model.fit(x_train, y_train, epochs=e, batch_size=bs, validation_data=(x_val,y_val),\n",
    "                        callbacks=[reduce_lr,early_stopping,mcp_save], verbose=2, shuffle=True)\n",
    "    histories.append(history)\n",
    "    k+=1\n",
    "    print('Current training time: {}'.format(time.time()-start_time))\n",
    "    \n",
    "print('Total training time: {}'.format(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(booster_model.metrics_names)\n",
    "scores = booster_model.evaluate(BoX_test, BoY_test, verbose=1)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(BoX_test.shape)\n",
    "print(BoY_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_trace = []\n",
    "# vloss_trace = []\n",
    "# for k in range(5):\n",
    "#     loss_trace.append(np.array(histories[k].history['loss']))\n",
    "#     vloss_trace.append(np.array(histories[k].history['val_loss']))\n",
    "# print(np.array(loss_trace).flatten())\n",
    "# plt.figure(figsize=(12,10))\n",
    "# plt.plot(np.array(loss_trace).flatten(), label='loss')\n",
    "# plt.plot(np.array(vloss_trace).flatten(), label='val_loss')\n",
    "# plt.title('model loss')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('epochs')\n",
    "# plt.legend(loc='upper right')\n",
    "# plt.yscale('log')\n",
    "# plt.savefig('{}.png'.format('models/loss_{}'.format(save_name)))\n",
    "\n",
    "ana.plot_test(booster_model,BoX_test,BoY_test,nvar=2,name='models/test_{}'.format(save_name),start=0,end=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "model=booster_model\n",
    "x_test=BoX_test\n",
    "y_test=BoY_test\n",
    "nvar=2\n",
    "name='test_diff'\n",
    "start=0\n",
    "end=15000\n",
    "x = np.linspace(start,end,int(end-start))\n",
    "Y_predict = model.predict(x_test[start:end,:,:])\n",
    "print(Y_predict.shape)\n",
    "fig, axs = plt.subplots(nvar,figsize=(16,16))\n",
    "for v in range (nvar):\n",
    "    Y_test_var1 = y_test[start:end,v].reshape(-1,1)\n",
    "    Y_predict_var1 = Y_predict[:,v].reshape(-1,1)\n",
    "    #axs[v].plot(Y_test_var1,Y_predict_var1,'o')\n",
    "    mape = 100*abs(Y_test_var1-Y_predict_var1)/Y_test_var1\n",
    "    print(x.shape)\n",
    "    print(mape.shape)\n",
    "    mape = mape.reshape(-1,)\n",
    "    print(mape.shape)\n",
    "    print('mape ave:{}'.format(mape.mean()))\n",
    "    axs[v].plot(Y_test_var1,label='Data')\n",
    "    axs[v].plot(Y_predict_var1, label='Prediction')\n",
    "    #axs[v].fill_between(x, mape, -mape, color='red',edgecolor=\"black\",alpha=0.5) \n",
    "    #axs[v].plot(mape)\n",
    "    axs[v].set_title(variables[v])\n",
    "    #axs[v].set_ylabel('MAPE')\n",
    "    axs[v].set_xlabel('Time samples')\n",
    "# plt.savefig('{}.png'.format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,figsize=(12,12))\n",
    "Y_test_var0 = data_list[0][0].inverse_transform(y_test[start:end,0].reshape(-1,1)).reshape(-1,1)\n",
    "Y_test_var1 = data_list[1][0].inverse_transform(y_test[start:end,1].reshape(-1,1)).reshape(-1,1)\n",
    "Y_predict_var0 = data_list[0][0].inverse_transform(Y_predict[:,0].reshape(-1,1)).reshape(-1,1)\n",
    "Y_predict_var1 = data_list[1][0].inverse_transform(Y_predict[:,1].reshape(-1,1)).reshape(-1,1)\n",
    "np_predict = np.concatenate((Y_test_var0,Y_test_var1,Y_predict_var0,Y_predict_var1),axis=concate_axis) \n",
    "df_cool = pd.DataFrame(np_predict,columns=['data_va0','data_va1','pred_va0','pred_va1'])\n",
    "#sns.pairplot(df_predict)\n",
    "#np_data = np.concatenate((Y_predict_var0,Y_predict_var1),axis=concate_axis) \n",
    "#df_data = pd.DataFrame(np_data)\n",
    "#sns.pairplot(df_data)\n",
    "sns.scatterplot(data=df_cool, x=\"data_va0\", y=\"data_va1\", label='Data')#, hue=\"time\")\n",
    "sns.scatterplot(data=df_cool, x=\"pred_va0\", y=\"pred_va1\", label='Digital Twin')#, hue=\"time\")\n",
    "\n",
    "#axs.plot(Y_test_var0,Y_test_var1,'o', label='Data')\n",
    "#axs.plot(Y_predict_var0,Y_predict_var1,'*', label='Digital Twin')\n",
    "axs.set_xlabel('B:VIMIN')\n",
    "axs.set_ylabel('B:IMINER')\n",
    "#plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 250 gives good results ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
